{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 12 Challenge\n",
    "## Deliverable 1: Scrape Titles and Preview Text from Mars News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "browser = Browser('chrome')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Visit the Website\n",
    "\n",
    "1. Use automated browsing to visit the [Mars news site](https://static.bc-edx.com/data/web/mars_news/index.html). Inspect the page to identify which elements to scrape.\n",
    "\n",
    "      > **Hint** To identify which elements to scrape, you might want to inspect the page by using Chrome DevTools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the Mars news site\n",
    "url = \"https://static.bc-edx.com/data/web/mars_news/index.html\"\n",
    "browser.visit(url)\n",
    "\n",
    "# Optional delay for loading the page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract HTML Code \n",
    "html = browser.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the Website\n",
    "\n",
    "Create a Beautiful Soup object and use it to extract text elements from the website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA Marks 25 Years Since Pathfinder Touched Down on Mars\n",
      "NASA's Perseverance Rover Captures Video of Solar Eclipse on Mars\n",
      "NASA, UAE Mars Missions Agree to Share Science Data\n",
      "Images and news content extracted from NASA's Mars News website on November 9, 2022.\n",
      "         Images used in accordance with the JPL Image Use Policy.\n",
      "This site is operated by edX Boot Camps LLC for educational purposes only.  \n",
      "            This is not a website endorsed by NASA. This website is intended only for internal academic purposes.\n"
     ]
    }
   ],
   "source": [
    "# Use BeautifulSoup methods to find and extract text elements from the webpage.\n",
    "paragraphs = soup.find_all('p')\n",
    "for paragraph in paragraphs:\n",
    "    print(paragraph.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Store the Results\n",
    "\n",
    "Extract the titles and preview text of the news articles that you scraped. Store the scraping results in Python data structures as follows:\n",
    "\n",
    "* Store each title-and-preview pair in a Python dictionary. And, give each dictionary two keys: `title` and `preview`. An example is the following:\n",
    "\n",
    "  ```python\n",
    "  {'title': \"NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\", \n",
    "   'preview': \"For the first time in its eight years orbiting Mars, NASA’s MAVEN mission witnessed two different types of ultraviolet aurorae simultaneously, the result of solar storms that began on Aug. 27.\"\n",
    "  }\n",
    "  ```\n",
    "\n",
    "* Store all the dictionaries in a Python list.\n",
    "\n",
    "* Print the list in your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"content_title\">NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm</div>\n"
     ]
    }
   ],
   "source": [
    "# Select one news article with select_one()\n",
    "slide_elem = soup.select_one('div.list_text')\n",
    "\n",
    "# Scrape the title of the news article\n",
    "title_elem = slide_elem.find('div', class_='content_title')\n",
    "print(title_elem)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NASA's MAVEN Observes Martian Light Show Caused by Major Solar Storm\n"
     ]
    }
   ],
   "source": [
    "# Extract the titles and preview text of the news articles\n",
    "title = title_elem.get_text()\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first time in its eight years orbiting Mars, NASA’s MAVEN mission witnessed two different types of ultraviolet aurorae simultaneously, the result of solar storms that began on Aug. 27.\n"
     ]
    }
   ],
   "source": [
    "# Scrape the preview text of the news article\n",
    "preview_elem = slide_elem.find('div', class_='article_teaser_body')\n",
    "preview = preview_elem.get_text()\n",
    "print(preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data has been exported to 'scraped_data.json' file.\n"
     ]
    }
   ],
   "source": [
    "# Alternative - Export scraped data into a JSON file\n",
    "import json\n",
    "\n",
    "# Create a dictionary to store the scraped data\n",
    "scraped_data = {\n",
    "    'title': title,\n",
    "    'preview': preview\n",
    "}\n",
    "\n",
    "# Serialize the dictionary to JSON format\n",
    "json_data = json.dumps(scraped_data)\n",
    "\n",
    "# Write the JSON data to a file\n",
    "with open('scraped_data.json', 'w') as file:\n",
    "    file.write(json_data)\n",
    "\n",
    "print(\"Scraped data has been exported to 'scraped_data.json' file.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
